import json
from typing import Dict, Any
from openai import OpenAI
from schema.interview import ExtractionJdMetrics as ExtractionMetrics
from ai_agents.llm.openai import OpenAI_LLM
from schema.jd_parser import jd_extraction_schema
from utils.config import API_KEY
llm = OpenAI_LLM(api_key=API_KEY)

class JobDescriptionExtractor:
    """
    Extract structured job requirements from job descriptions
    Returns skills, qualifications, experience, responsibilities, etc.
    
    Supports:
    - Technical and soft skills extraction
    - Required vs. preferred qualifications
    - Experience level requirements
    - Responsibilities and duties
    - Salary/compensation info
    - Benefits
    """
    
    # GPT-4o-mini pricing
    INPUT_PRICE_PER_1K = 0.000150
    OUTPUT_PRICE_PER_1K = 0.000600
    
    def __init__(self, openai_api_key: str, model: str = "gpt-4o-mini"):
        """
        Initialize job description extractor
        
        Args:
            openai_api_key: Your OpenAI API key
            model: OpenAI model to use
        """
        self.client = OpenAI(api_key=openai_api_key)
        self.model = model
        self.schema = self._get_schema()
        
        # Metrics
        self.api_calls = 0
        self.input_tokens = 0
        self.output_tokens = 0
    
    def _get_schema(self) -> dict:
        """JSON schema for structured job requirement extraction"""
        return jd_extraction_schema
    
    def extract(self, job_description: str, verbose: bool = True) -> tuple[Dict[str, Any], ExtractionMetrics]:
        """
        Extract structured requirements from job description
        
        Args:
            job_description: Raw job description text
            verbose: Print extraction progress
            
        Returns:
            (extracted_data, metrics)
        """
        if verbose:
            print("ðŸš€ Starting job requirement extraction...")
            print(f"ðŸ“„ Model: {self.model}\n")
        
        # Reset metrics
        self.api_calls = 0
        self.input_tokens = 0
        self.output_tokens = 0
        
        # Extract requirements
        if verbose:
            print("ðŸ“‹ Parsing job description...")
        
        extracted_data = self._extract_requirements(job_description)
        
        # Calculate metrics
        cost = self._calculate_cost()
        
        metrics = ExtractionMetrics(
            api_calls=self.api_calls,
            input_tokens=self.input_tokens,
            output_tokens=self.output_tokens,
            cost_estimate=cost
        )
        
        if verbose:
            print("âœ… Extraction complete!\n")
            print(metrics)
        
        return extracted_data, metrics
    
    def _extract_requirements(self, job_description: str) -> Dict[str, Any]:
        """Extract requirements using GPT-4o-mini with structured output"""
        messages = [
            {
                "role": "system",
                "content": """You are an expert job description analyzer. Extract ALL job requirements and information from the provided job description.
                
                Extract information systematically:
                - Identify required vs preferred skills and qualifications
                - Extract technical and soft skills
                - List key responsibilities
                - Identify education and certification requirements
                - Extract salary, benefits, and location info
                - Determine remote status and job type

                Use empty strings "" for missing text fields and empty arrays [] for missing lists."""
            },
            {
                "role": "user",
                "content": f"Extract structured job requirements from this job description:\n\n{job_description}"
            }
        ]
        
        response = llm.generate_json(
            messages=messages,
            model=self.model,
            schema=self.schema
        )
        
        # Track metrics
        self.api_calls += 1
        self.input_tokens += response.usage.prompt_tokens
        self.output_tokens += response.usage.completion_tokens
        
        return json.loads(response.choices[0].message.content)
    
    def extract_to_file(self, job_description: str, output_file: str, verbose: bool = True) -> None:
        """Extract and save results to JSON file"""
        extracted_data, metrics = self.extract(job_description, verbose)
        
        with open(output_file, 'w') as f:
            json.dump(extracted_data, f, indent=2)
        
        if verbose:
            print(f"ðŸ’¾ Results saved to: {output_file}\n")
    
    def _calculate_cost(self) -> float:
        """Calculate estimated cost based on token usage"""
        input_cost = (self.input_tokens / 1000) * self.INPUT_PRICE_PER_1K
        output_cost = (self.output_tokens / 1000) * self.OUTPUT_PRICE_PER_1K
        return input_cost + output_cost
