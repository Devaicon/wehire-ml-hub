{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4defe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "API_KEY = \"API_KEY\"\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello! Can you help me with a Python code snippet?\"}\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fcace7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CUYTRqV4NzhyfPqG59fwKYxlVJVZ5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Of course! I'd be happy to help. What do you need assistance with in your Python code snippet?\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761398393, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=22, prompt_tokens=29, total_tokens=51, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2dccf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import base64\n",
    "\n",
    "class LLM(ABC):\n",
    "    \"\"\"\n",
    "    Abstract class for Large Language Models (LLMs).\n",
    "    This class defines a common interface for different LLM providers.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def chat(self, messages: list, model: str = \"default_model\"):\n",
    "        \"\"\"Abstract method to send messages to the LLM and receive responses.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def chat_stream(self, messages: list, model: str = \"default_model\"):\n",
    "        \"\"\"Abstract method to send messages to the LLM and receive responses.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_json(self, messages: list, model: str = \"default_model\"):\n",
    "        \"\"\"Abstract method to send messages to the LLM and receive responses.\"\"\"\n",
    "        pass\n",
    "\n",
    "class OpenAI_LLM(LLM):\n",
    "    \"\"\"Implementation of the LLM interface for OpenAI's GPT models.\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "    def chat(self, messages: list, model: str = \"gpt-4o\"): # type: ignore\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            stream=False,  # Ensures response isn't streamed\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def chat_stream(self, messages: list, model: str = \"gpt-4o\"): # type: ignore\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            stream=True,\n",
    "        )\n",
    "        for chunk in response:\n",
    "            if chunk.choices[0].delta.content or chunk.choices[0].finish_reason:\n",
    "                yield {\n",
    "                    \"content\": chunk.choices[0].delta.content,\n",
    "                    \"finish_reason\": chunk.choices[0].finish_reason,\n",
    "                }\n",
    "\n",
    "    def generate_json(self, messages: list, schema: dict, model: str = \"gpt-4o\"): # type: ignore\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": schema,\n",
    "            }, # type: ignore\n",
    "            stream=False,  # Ensures response isn't streamed\n",
    "        ) # type: ignore\n",
    "        # response.choices[0].message.content\n",
    "        return response\n",
    "    \n",
    "    def generate_stream_json(self, messages: list, model: str = \"gpt-4o\"): # type: ignore\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            stream=True,  # Ensures response isn't streamed\n",
    "        )\n",
    "        for chunk in response:\n",
    "            if chunk.choices[0].delta.content or chunk.choices[0].finish_reason:\n",
    "                yield {\n",
    "                    \"content\": chunk.choices[0].delta.content,\n",
    "                    \"finish_reason\": chunk.choices[0].finish_reason,\n",
    "                }\n",
    "    def extract_text_from_image(self, img_bytes: base64) -> str: # type: ignore\n",
    "        \n",
    "\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        { \"type\": \"input_text\", \"text\": \"Extract text clearly from this image.\" },\n",
    "                        {\n",
    "                            \"type\": \"input_image\",\n",
    "                            \"image_url\": f\"data:image/jpeg;base64,{img_bytes}\",\n",
    "                        },\n",
    "                    ],\n",
    "                } # type: ignore\n",
    "            ],\n",
    "        )\n",
    "        # self.api_calls += 1\n",
    "        return response.output_text # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ed5c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI_LLM(api_key=API_KEY)\n",
    "\n",
    "# response = llm.chat(\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts information from resumes.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Extract the key details from this resume...\"}\n",
    "#     ],\n",
    "#     model=\"gpt-4o-mini\"\n",
    "# )\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f514e21",
   "metadata": {},
   "source": [
    "# PDF Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0cdb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Optimized Parallel Resume Extractor for GPT-4o-mini\n",
    "Best for 10-30 page documents with parallel chunk processing\n",
    "\n",
    "Dependencies:\n",
    "- Required: openai, PyMuPDF (fitz)\n",
    "- Optional: pytesseract, Pillow (for Tesseract OCR mode)\n",
    "- Optional: Pillow (for Vision API mode)\n",
    "\n",
    "Install:\n",
    "  pip install openai PyMuPDF\n",
    "  \n",
    "Optional for image-based PDFs:\n",
    "  pip install Pillow pytesseract\n",
    "\"\"\"\n",
    "\n",
    "import io\n",
    "import fitz\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Optional dependencies\n",
    "try:\n",
    "    import pytesseract\n",
    "    TESSERACT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TESSERACT_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "    import base64\n",
    "    from io import BytesIO\n",
    "    PILLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PILLOW_AVAILABLE = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExtractionMetrics:\n",
    "    \"\"\"Track extraction performance metrics\"\"\"\n",
    "    total_pages: int\n",
    "    chunks_processed: int\n",
    "    api_calls: int\n",
    "    total_time: float\n",
    "    cost_estimate: float\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘          EXTRACTION METRICS                  â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ Total Pages:      {self.total_pages:>4}      â•‘\n",
    "â•‘ Chunks Processed: {self.chunks_processed:>4} â•‘\n",
    "â•‘ API Calls:        {self.api_calls:>4}        â•‘\n",
    "â•‘ Time Elapsed:     {self.total_time:>6.2f}s   â•‘\n",
    "â•‘ Est. Cost:        ${self.cost_estimate:>6.4f}â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class OptimizedResumeExtractor:\n",
    "    \"\"\"\n",
    "    High-performance resume extractor optimized for GPT-4o-mini\n",
    "    - Parallel chunk processing\n",
    "    - Smart token management\n",
    "    - Cost optimization\n",
    "    - Fast merging algorithm\n",
    "    \n",
    "    Supports multiple extraction modes:\n",
    "    - TEXT: Fast text extraction (always available)\n",
    "    - VISION: GPT-4 Vision API (requires Pillow)\n",
    "    - TESSERACT: Tesseract OCR + LLM (requires pytesseract + Pillow)\n",
    "    - AUTO: Automatic mode selection\n",
    "    \"\"\"\n",
    "    \n",
    "    # GPT-4o-mini pricing (as of 2024)\n",
    "    INPUT_PRICE_PER_1K = 0.000150   # $0.15 per 1M tokens\n",
    "    OUTPUT_PRICE_PER_1K = 0.000600  # $0.60 per 1M tokens\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        openai_api_key: str,\n",
    "        pages_per_chunk: int = 5,\n",
    "        max_workers: int = 5,\n",
    "        model: str = \"gpt-4o-mini\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize extractor\n",
    "        \n",
    "        Args:\n",
    "            openai_api_key: Your OpenAI API key\n",
    "            pages_per_chunk: Pages to process per chunk (3-7 recommended)\n",
    "            max_workers: Parallel threads (5-10 recommended)\n",
    "            model: OpenAI model to use\n",
    "        \"\"\"\n",
    "        self.client = OpenAI(api_key=openai_api_key)\n",
    "        self.pages_per_chunk = pages_per_chunk\n",
    "        self.max_workers = max_workers\n",
    "        self.model = model\n",
    "        self.schema = self._get_schema()\n",
    "        \n",
    "        # Metrics\n",
    "        self.api_calls = 0\n",
    "        self.input_tokens = 0\n",
    "        self.output_tokens = 0\n",
    "        \n",
    "        # Check optional dependencies\n",
    "        self._check_dependencies()\n",
    "    \n",
    "    def _check_dependencies(self):\n",
    "        \"\"\"Check and warn about optional dependencies\"\"\"\n",
    "        if not PILLOW_AVAILABLE:\n",
    "            warnings.warn(\n",
    "                \"Pillow not installed. Vision and Tesseract modes will be unavailable.\\n\"\n",
    "                \"Install with: pip install Pillow\",\n",
    "                ImportWarning\n",
    "            )\n",
    "        \n",
    "        if not TESSERACT_AVAILABLE:\n",
    "            warnings.warn(\n",
    "                \"pytesseract not installed. Tesseract mode will be unavailable.\\n\"\n",
    "                \"Install with: pip install pytesseract\\n\"\n",
    "                \"Also install Tesseract OCR: https://github.com/tesseract-ocr/tesseract\",\n",
    "                ImportWarning\n",
    "            )\n",
    "    \n",
    "    def get_available_modes(self) -> List[str]:\n",
    "        \"\"\"Get list of available extraction modes based on installed dependencies\"\"\"\n",
    "        modes = [\"text\", \"auto\"]  # Always available\n",
    "        \n",
    "        if PILLOW_AVAILABLE:\n",
    "            modes.append(\"vision\")\n",
    "        \n",
    "        if PILLOW_AVAILABLE and TESSERACT_AVAILABLE:\n",
    "            modes.append(\"tesseract\")\n",
    "        \n",
    "        return modes\n",
    "    \n",
    "    def _get_schema(self) -> dict:\n",
    "        \"\"\"Extraction schema for structured output\"\"\"\n",
    "        return {\n",
    "            \"name\": \"resume_extraction\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"personal_info\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"full_name\": {\"type\": \"string\"},\n",
    "                            \"email\": {\"type\": \"string\"},\n",
    "                            \"phone\": {\"type\": \"string\"},\n",
    "                            \"linkedin\": {\"type\": \"string\"},\n",
    "                            \"github\": {\"type\": \"string\"},\n",
    "                            \"portfolio\": {\"type\": \"string\"},\n",
    "                            \"location\": {\"type\": \"string\"}\n",
    "                        },\n",
    "                        \"required\": [\"full_name\", \"email\", \"phone\", \"linkedin\", \"github\", \"portfolio\", \"location\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"professional_summary\": {\"type\": \"string\"},\n",
    "                    \"skills\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"experience\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"company\": {\"type\": \"string\"},\n",
    "                                \"position\": {\"type\": \"string\"},\n",
    "                                \"location\": {\"type\": \"string\"},\n",
    "                                \"start_date\": {\"type\": \"string\"},\n",
    "                                \"end_date\": {\"type\": \"string\"},\n",
    "                                \"duration\": {\"type\": \"string\"},\n",
    "                                \"responsibilities\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\"type\": \"string\"}\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"company\", \"position\", \"location\", \"start_date\", \"end_date\", \"duration\", \"responsibilities\"],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    },\n",
    "                    \"education\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"institution\": {\"type\": \"string\"},\n",
    "                                \"degree\": {\"type\": \"string\"},\n",
    "                                \"field_of_study\": {\"type\": \"string\"},\n",
    "                                \"graduation_year\": {\"type\": \"string\"},\n",
    "                                \"gpa\": {\"type\": \"string\"},\n",
    "                                \"location\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"required\": [\"institution\", \"degree\", \"field_of_study\", \"graduation_year\", \"gpa\", \"location\"],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    },\n",
    "                    \"certifications\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"name\": {\"type\": \"string\"},\n",
    "                                \"issuer\": {\"type\": \"string\"},\n",
    "                                \"date\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"required\": [\"name\", \"issuer\", \"date\"],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    },\n",
    "                    \"projects\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"name\": {\"type\": \"string\"},\n",
    "                                \"description\": {\"type\": \"string\"},\n",
    "                                \"technologies\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\"type\": \"string\"}\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"name\", \"description\", \"technologies\"],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    },\n",
    "                    \"languages\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"personal_info\", \"professional_summary\", \"skills\", \"experience\", \"education\", \"certifications\", \"projects\", \"languages\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def extract_from_pdf(self, pdf_path: str, ocr_method: str = \"tesseract\",verbose: bool = True) -> tuple[Dict[str, Any], ExtractionMetrics]:\n",
    "        \"\"\"\n",
    "        Extract resume data from PDF with parallel processing\n",
    "        \n",
    "        Returns:\n",
    "            (extracted_data, metrics)\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        self.api_calls = 0\n",
    "        self.input_tokens = 0\n",
    "        self.output_tokens = 0\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"ðŸš€ Starting resume extraction...\")\n",
    "            print(f\"ðŸ“„ Model: {self.model}\")\n",
    "            print(f\"âš™ï¸  Config: {self.pages_per_chunk} pages/chunk, {self.max_workers} workers\\n\")\n",
    "        \n",
    "        # Step 1: Extract text from PDF\n",
    "        if verbose:\n",
    "            print(\"ðŸ“– Reading PDF...\")\n",
    "        doc = fitz.open(pdf_path)\n",
    "        pages_text = []\n",
    "        for page_num in range(len(doc)):\n",
    "            text = doc[page_num].get_text()\n",
    "            if not text.strip():  # type: ignore # If page has no text, try OCR\n",
    "                if ocr_method != \"none\":\n",
    "                    if verbose:\n",
    "                        print(f\"ðŸ” Page {page_num + 1} is scanned, trying OCR via {ocr_method}...\")\n",
    "                    page_image = doc[page_num].get_pixmap()\n",
    "\n",
    "                    if ocr_method == \"tesseract\":\n",
    "                        text = self._extract_with_tesseract(page_image)\n",
    "                        print(\"Tesseract OCR Result:\", text)\n",
    "\n",
    "                    elif ocr_method == \"vision\":\n",
    "                        text = self._extract_with_vision(page_image)\n",
    "                        print(\"Vision OCR Result:\", text)\n",
    "\n",
    "            if text.strip():  # type: ignore # Only include non-empty pages\n",
    "                pages_text.append(text)\n",
    "        doc.close()\n",
    "        \n",
    "        num_pages = len(pages_text)\n",
    "        if verbose:\n",
    "            print(f\"âœ“  Extracted {num_pages} pages\\n\")\n",
    "        \n",
    "        # Step 2: Create chunks\n",
    "        chunks = self._create_chunks(pages_text)\n",
    "        if verbose:\n",
    "            print(f\"ðŸ“¦ Created {len(chunks)} chunks for parallel processing\\n\")\n",
    "        \n",
    "        # Step 3: Parallel extraction\n",
    "        if verbose:\n",
    "            print(\"âš¡ Processing chunks in parallel...\")\n",
    "        partial_results = self._extract_parallel(chunks, verbose)\n",
    "        \n",
    "        # Step 4: Merge results\n",
    "        if verbose:\n",
    "            print(\"\\nðŸ”„ Merging results...\")\n",
    "        merged_result = self._merge_results(partial_results)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        elapsed = time.time() - start_time\n",
    "        cost = self._calculate_cost()\n",
    "        \n",
    "        metrics = ExtractionMetrics(\n",
    "            total_pages=num_pages,\n",
    "            chunks_processed=len(chunks),\n",
    "            api_calls=self.api_calls,\n",
    "            total_time=elapsed,\n",
    "            cost_estimate=cost\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"âœ… Extraction complete!\\n\")\n",
    "            print(metrics)\n",
    "        \n",
    "        return merged_result, metrics\n",
    "    \n",
    "    def _extract_with_tesseract(self, page_image):\n",
    "        img = Image.frombytes(\"RGB\", [page_image.width, page_image.height], page_image.samples) # type: ignore\n",
    "        img.show()\n",
    "        return pytesseract.image_to_string(img) # type: ignore\n",
    "\n",
    "    def _extract_with_vision(self, page_image):\n",
    "        # Convert Pixmap â†’ PNG bytes\n",
    "        img = Image.frombytes(\"RGB\", (page_image.width, page_image.height), page_image.samples) # type: ignore\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=\"PNG\")\n",
    "        img_bytes = buffer.getvalue()\n",
    "        img_base64 = base64.b64encode(img_bytes).decode(\"utf-8\") # type: ignore\n",
    "        return llm.extract_text_from_image(img_base64) # type: ignore\n",
    "\n",
    "\n",
    "    def _create_chunks(self, pages_text: List[str]) -> List[str]:\n",
    "        \"\"\"Create optimal chunks from pages\"\"\"\n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        \n",
    "        for i, page_text in enumerate(pages_text):\n",
    "            current_chunk.append(page_text)\n",
    "            \n",
    "            # Create chunk when reaching target size or last page\n",
    "            if len(current_chunk) >= self.pages_per_chunk or i == len(pages_text) - 1:\n",
    "                chunks.append(\"\\n\\n--- PAGE BREAK ---\\n\\n\".join(current_chunk))\n",
    "                current_chunk = []\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def _extract_parallel(self, chunks: List[str], verbose: bool = True) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Extract data from chunks in parallel\"\"\"\n",
    "        results = []\n",
    "        completed = 0\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            future_to_chunk = {\n",
    "                executor.submit(self._extract_chunk, i, chunk): i \n",
    "                for i, chunk in enumerate(chunks)\n",
    "            }\n",
    "            \n",
    "            # Process as they complete\n",
    "            for future in as_completed(future_to_chunk):\n",
    "                chunk_idx = future_to_chunk[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    results.append((chunk_idx, result))\n",
    "                    completed += 1\n",
    "                    if verbose:\n",
    "                        print(f\"  âœ“ Chunk {completed}/{len(chunks)} processed\")\n",
    "                except Exception as e:\n",
    "                    if verbose:\n",
    "                        print(f\"  âœ— Chunk {chunk_idx + 1} failed: {e}\")\n",
    "                    results.append((chunk_idx, self._empty_result()))\n",
    "        \n",
    "        # Sort by original chunk order\n",
    "        results.sort(key=lambda x: x[0])\n",
    "        return [r[1] for r in results]\n",
    "    \n",
    "    def _extract_chunk(self, chunk_idx: int, chunk_text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract data from a single chunk\"\"\"\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert resume parser. Extract ALL information from this resume section accurately. Use empty strings \\\"\\\" for missing text fields and empty arrays [] for missing lists.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Extract resume information from this text:\\n\\n{chunk_text}\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # response = self.client.chat.completions.create(\n",
    "        #     model=self.model,\n",
    "        #     messages=messages,\n",
    "        #     response_format={\n",
    "        #         \"type\": \"json_schema\",\n",
    "        #         \"json_schema\": self.schema\n",
    "        #     }\n",
    "        # )\n",
    "        response = llm.generate_json(\n",
    "            messages=messages,\n",
    "            model=self.model,\n",
    "            schema=self.schema\n",
    "        )\n",
    "        # Track metrics\n",
    "        self.api_calls += 1\n",
    "        self.input_tokens += response.usage.prompt_tokens\n",
    "        self.output_tokens += response.usage.completion_tokens\n",
    "        \n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    \n",
    "    def _empty_result(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return empty result structure\"\"\"\n",
    "        return {\n",
    "            \"personal_info\": {\n",
    "                \"full_name\": \"\",\n",
    "                \"email\": \"\",\n",
    "                \"phone\": \"\",\n",
    "                \"linkedin\": \"\",\n",
    "                \"github\": \"\",\n",
    "                \"portfolio\": \"\",\n",
    "                \"location\": \"\"\n",
    "            },\n",
    "            \"professional_summary\": \"\",\n",
    "            \"skills\": [],\n",
    "            \"experience\": [],\n",
    "            \"education\": [],\n",
    "            \"certifications\": [],\n",
    "            \"projects\": [],\n",
    "            \"languages\": []\n",
    "        }\n",
    "    \n",
    "    def _merge_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Intelligently merge multiple partial results\n",
    "        Optimized merging algorithm for speed\n",
    "        \"\"\"\n",
    "        merged = self._empty_result()\n",
    "        \n",
    "        # Merge personal info (first non-null wins)\n",
    "        for result in results:\n",
    "            for key, value in result.get(\"personal_info\", {}).items():\n",
    "                if value and not merged[\"personal_info\"].get(key):\n",
    "                    merged[\"personal_info\"][key] = value\n",
    "        \n",
    "        # Merge professional summary (longest wins)\n",
    "        summaries = [r.get(\"professional_summary\") for r in results if r.get(\"professional_summary\")]\n",
    "        if summaries:\n",
    "            merged[\"professional_summary\"] = max(summaries, key=len) # type: ignore\n",
    "        \n",
    "        # Merge skills (deduplicate, case-insensitive)\n",
    "        skills_set = set()\n",
    "        skills_map = {}  # lowercase -> original case\n",
    "        for result in results:\n",
    "            for skill in result.get(\"skills\", []):\n",
    "                skill_lower = skill.lower()\n",
    "                if skill_lower not in skills_set:\n",
    "                    skills_set.add(skill_lower)\n",
    "                    skills_map[skill_lower] = skill\n",
    "        merged[\"skills\"] = sorted(skills_map.values())\n",
    "        \n",
    "        # Merge languages (deduplicate)\n",
    "        langs_set = set()\n",
    "        for result in results:\n",
    "            langs_set.update(result.get(\"languages\", []))\n",
    "        merged[\"languages\"] = sorted(list(langs_set))\n",
    "        \n",
    "        # Merge experience (deduplicate by company+position)\n",
    "        seen_exp = set()\n",
    "        for result in results:\n",
    "            for exp in result.get(\"experience\", []):\n",
    "                key = (exp.get(\"company\", \"\").lower(), exp.get(\"position\", \"\").lower())\n",
    "                if key not in seen_exp and key != (\"\", \"\"):\n",
    "                    seen_exp.add(key)\n",
    "                    merged[\"experience\"].append(exp)\n",
    "        \n",
    "        # Merge education (deduplicate by institution+degree)\n",
    "        seen_edu = set()\n",
    "        for result in results:\n",
    "            for edu in result.get(\"education\", []):\n",
    "                key = (edu.get(\"institution\", \"\").lower(), edu.get(\"degree\", \"\").lower())\n",
    "                if key not in seen_edu and key != (\"\", \"\"):\n",
    "                    seen_edu.add(key)\n",
    "                    merged[\"education\"].append(edu)\n",
    "        \n",
    "        # Merge certifications (deduplicate by name)\n",
    "        seen_certs = set()\n",
    "        for result in results:\n",
    "            for cert in result.get(\"certifications\", []):\n",
    "                cert_name = cert.get(\"name\", \"\").lower()\n",
    "                if cert_name and cert_name not in seen_certs:\n",
    "                    seen_certs.add(cert_name)\n",
    "                    merged[\"certifications\"].append(cert)\n",
    "        \n",
    "        # Merge projects (deduplicate by name)\n",
    "        seen_projects = set()\n",
    "        for result in results:\n",
    "            for proj in result.get(\"projects\", []):\n",
    "                proj_name = proj.get(\"name\", \"\").lower()\n",
    "                if proj_name and proj_name not in seen_projects:\n",
    "                    seen_projects.add(proj_name)\n",
    "                    merged[\"projects\"].append(proj)\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    def _calculate_cost(self) -> float:\n",
    "        \"\"\"Calculate estimated cost based on token usage\"\"\"\n",
    "        input_cost = (self.input_tokens / 1000) * self.INPUT_PRICE_PER_1K\n",
    "        output_cost = (self.output_tokens / 1000) * self.OUTPUT_PRICE_PER_1K\n",
    "        return input_cost + output_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b690c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'personal_info': {'full_name': 'Faizan Munsaf',\n",
       "  'email': 'faizanmunsaf@gmail.com',\n",
       "  'phone': '+92-3328893064',\n",
       "  'linkedin': 'FaizanMunsaf-Linkedin',\n",
       "  'github': 'FaizanMunsaf-GitHub',\n",
       "  'portfolio': '',\n",
       "  'location': 'Sodiwal Bund Road Lahore, Pakistan'},\n",
       " 'professional_summary': \"I am a driven and talented professional who brings a unique blend of strategic thinking, catalytic energy, empathetic understanding, and critical thinking to everything I do. With a strong educational background, including a Bachelor's degree in Computer Science and certification in Machine Learning, Natural Language Processing, Python Development and Deep Learning, I have developed a comprehensive skill set in the field of technology as a Backend Developer with Django, FastAPI and Flask. My exceptional problem-solving skills and excellent communication abilities make me a valuable asset to any team.\",\n",
       " 'skills': ['C++',\n",
       "  'Deep Learning',\n",
       "  'Django',\n",
       "  'FastAPI',\n",
       "  'Flask',\n",
       "  'GenAi',\n",
       "  'JWT Authentication',\n",
       "  'JavaScript',\n",
       "  'MVC',\n",
       "  'MVT',\n",
       "  'Machine Learning',\n",
       "  'MongoDB',\n",
       "  'MySQL',\n",
       "  'NLP',\n",
       "  'OOD',\n",
       "  'OOP',\n",
       "  'Postgresql',\n",
       "  'PyTorch',\n",
       "  'Pycharm',\n",
       "  'Python',\n",
       "  'Sqlite',\n",
       "  'TensorFlow',\n",
       "  'VS Code',\n",
       "  'Web Application Security Best Practices',\n",
       "  'git version control'],\n",
       " 'experience': [{'company': 'Software Alliance',\n",
       "   'position': 'Machine Learning Engineer & FullStack Developer (Full Stack Developer | Gen AI | NLP)',\n",
       "   'location': '',\n",
       "   'start_date': 'Oct 2021',\n",
       "   'end_date': 'Sep 2024',\n",
       "   'duration': '',\n",
       "   'responsibilities': ['Proficient in leveraging large language models to achieve optimized results, with a focus on improving performance through fine-tuning and advanced techniques.',\n",
       "    'Skilled in dataset preprocessing, keyword extraction, beam search, text indexing (Llama-index, Langchain), and custom model creation.',\n",
       "    'Experienced with RNNs, RagModels, MMR algorithms, and fine-tuning pretrained models using techniques like PEFT, QLORA, ALPHACLORA, and PPO.',\n",
       "    'Expertise in designing and building backend architectures for web-based applications using FastAPI, Flask, and Node.js (TypeScript).',\n",
       "    'Proficient with databases such as MySQL, MongoDB (NoSQL), PostgreSQL, and SQLite.',\n",
       "    'Experienced in developing the frontend architecture and programming using Next.js and React.js to build responsive, scalable, and interactive web applications.']},\n",
       "  {'company': 'PieCyfer',\n",
       "   'position': 'Python Developer (Backend Django Developer | NLP)',\n",
       "   'location': '',\n",
       "   'start_date': 'Sep 2024',\n",
       "   'end_date': 'Jan 2025',\n",
       "   'duration': '',\n",
       "   'responsibilities': ['Developed Python Django Ninja templates for backend handling with Docker microservices following MVVT design patterns.',\n",
       "    'Wrote database migrations, custom commands, and backend services to streamline development processes.',\n",
       "    'Implemented intermediate backend Python development tasks at PieCyfer.',\n",
       "    'Collaborated with the team to support and enhance backend functionalities for optimal performance.',\n",
       "    'Optimized code for performance and scalability while managing Git version control on AWS servers.',\n",
       "    'Utilized Python skills to contribute to the development of efficient, scalable, and maintainable solutions.']}],\n",
       " 'education': [{'institution': 'Superior University Lahore',\n",
       "   'degree': 'B.S.C.S.',\n",
       "   'field_of_study': 'Computer Science',\n",
       "   'graduation_year': 'Jun 2023',\n",
       "   'gpa': '3.56/4.0',\n",
       "   'location': ''},\n",
       "  {'institution': 'Govt. Commerce College',\n",
       "   'degree': 'H.S.S.C.',\n",
       "   'field_of_study': 'Intermediate of Computer Science',\n",
       "   'graduation_year': 'Jun 2019',\n",
       "   'gpa': '',\n",
       "   'location': ''},\n",
       "  {'institution': 'Hamiyat - e - Islam Higher Secondary School',\n",
       "   'degree': 'S.S.C.',\n",
       "   'field_of_study': 'Computer Science',\n",
       "   'graduation_year': 'Jun 2017',\n",
       "   'gpa': '',\n",
       "   'location': ''}],\n",
       " 'certifications': [{'name': 'Generative AI: Working with Large Language Models',\n",
       "   'issuer': 'LinkedIn',\n",
       "   'date': ''},\n",
       "  {'name': 'Nano Tips for Effortless Influence with ShadÃ© Zahrai',\n",
       "   'issuer': 'LinkedIn',\n",
       "   'date': ''},\n",
       "  {'name': 'Prompt Engineering for ChatGPT', 'issuer': 'Coursera', 'date': ''},\n",
       "  {'name': 'Generative AI with Large Language Models',\n",
       "   'issuer': 'Coursera',\n",
       "   'date': ''},\n",
       "  {'name': 'Introduction to Deep Learning & Neural Networks with Keras',\n",
       "   'issuer': 'Coursera',\n",
       "   'date': ''},\n",
       "  {'name': 'Python for Data Science, AI & Development',\n",
       "   'issuer': 'Coursera',\n",
       "   'date': ''},\n",
       "  {'name': 'Question Generation Using Natural Language Processing',\n",
       "   'issuer': 'Udemy',\n",
       "   'date': ''},\n",
       "  {'name': 'Machine Learning with Python', 'issuer': 'Coursera', 'date': ''},\n",
       "  {'name': 'Fundamentals of Deep Learning', 'issuer': 'Nvidia', 'date': ''}],\n",
       " 'projects': [{'name': 'AllahuAlam',\n",
       "   'description': 'Implemented the MVC (Model-View-Controller) Design Pattern to streamline workflow and ensure efficient application functionality. Users can interact with their selected bots, which provide precise responses tailored to the specified index.',\n",
       "   'technologies': ['Python', 'NLP', 'ML', 'GenAI', 'FastAPI', 'NextJs']},\n",
       "  {'name': 'AutoQuiz',\n",
       "   'description': 'A platform where users can upload books and our model generates multiple-choice questions (MCQs) from the provided content, significantly benefiting teachers.',\n",
       "   'technologies': ['Python', 'NLP', 'ML', 'GenAI', 'FastAPI', 'ReactJs']},\n",
       "  {'name': 'Krytron',\n",
       "   'description': 'Developing a groundbreaking banking application integrated with a Secure Payment Methods platform to ensure safe and seamless transactions.',\n",
       "   'technologies': ['Node.js',\n",
       "    'TypeScript',\n",
       "    'MVC',\n",
       "    'Express',\n",
       "    'Private BlockChain']},\n",
       "  {'name': 'TikTok Bot',\n",
       "   'description': 'Developed a bot that automates TikTok account logins and performs random activities on the platform.',\n",
       "   'technologies': ['Python', 'Selenium', 'Automation']},\n",
       "  {'name': 'Amaizing.io',\n",
       "   'description': 'Developed a tracking system to monitor user products from Amazon, utilizing Python Django Ninja.',\n",
       "   'technologies': ['Python',\n",
       "    'Django Ninja',\n",
       "    'NLP',\n",
       "    'Amazon Rainforest-api']}],\n",
       " 'languages': []}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize extractor\n",
    "extractor = OptimizedResumeExtractor(\n",
    "    openai_api_key=API_KEY,\n",
    "    pages_per_chunk=5,      # 5 pages per chunk (optimal for 10-30 pages)\n",
    "    max_workers=5,          # 5 parallel workers\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# Extract resume\n",
    "result, metrics = extractor.extract_from_pdf(\"resume.pdf\", ocr_method=\"tesseract\", verbose=True)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTED DATA\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Name: {result['personal_info'].get('full_name', 'N/A')}\")\n",
    "print(f\"Email: {result['personal_info'].get('email', 'N/A')}\")\n",
    "print(f\"Phone: {result['personal_info'].get('phone', 'N/A')}\")\n",
    "print(f\"\\nSkills ({len(result['skills'])}): {', '.join(result['skills'][:10])}...\")\n",
    "print(f\"\\nExperience ({len(result['experience'])} positions):\")\n",
    "for exp in result['experience'][:3]:\n",
    "    print(f\"  â€¢ {exp['position']} at {exp['company']}\")\n",
    "print(f\"\\nEducation ({len(result['education'])} entries):\")\n",
    "for edu in result['education']:\n",
    "    print(f\"  â€¢ {edu['degree']} from {edu['institution']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Performance comparison for different configurations\n",
    "# print(\"\\n\\n\" + \"=\"*60)\n",
    "# print(\"CONFIGURATION COMPARISON\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# configs = [\n",
    "#     {\"pages_per_chunk\": 3, \"max_workers\": 3},\n",
    "#     {\"pages_per_chunk\": 5, \"max_workers\": 5},\n",
    "#     {\"pages_per_chunk\": 7, \"max_workers\": 5},\n",
    "# ]\n",
    "\n",
    "# for config in configs:\n",
    "#     print(f\"\\nðŸ“Š Testing: {config['pages_per_chunk']} pages/chunk, {config['max_workers']} workers\")\n",
    "#     test_extractor = OptimizedResumeExtractor(\n",
    "#         openai_api_key=API_KEY,         **config,\n",
    "#         model=\"gpt-4o-mini\"\n",
    "#     )\n",
    "#     _, test_metrics = test_extractor.extract_from_pdf(\"scanned_resume.pdf\", ocr_method=\"tesseract\",verbose=False)\n",
    "#     print(f\"   Time: {test_metrics.total_time:.2f}s | Chunks: {test_metrics.chunks_processed} | Cost: ${test_metrics.cost_estimate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf5e20",
   "metadata": {},
   "source": [
    "# Job Description Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44cf4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any\n",
    "from openai import OpenAI\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExtractionMetrics:\n",
    "    \"\"\"Track extraction performance metrics\"\"\"\n",
    "    api_calls: int\n",
    "    input_tokens: int\n",
    "    output_tokens: int\n",
    "    cost_estimate: float\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘      JOB EXTRACTION METRICS                  â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ API Calls:        {self.api_calls:>4}        â•‘\n",
    "â•‘ Input Tokens:     {self.input_tokens:>4}     â•‘\n",
    "â•‘ Output Tokens:    {self.output_tokens:>4}    â•‘\n",
    "â•‘ Est. Cost:        ${self.cost_estimate:>6.4f}â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class JobDescriptionExtractor:\n",
    "    \"\"\"\n",
    "    Extract structured job requirements from job descriptions\n",
    "    Returns skills, qualifications, experience, responsibilities, etc.\n",
    "    \n",
    "    Supports:\n",
    "    - Technical and soft skills extraction\n",
    "    - Required vs. preferred qualifications\n",
    "    - Experience level requirements\n",
    "    - Responsibilities and duties\n",
    "    - Salary/compensation info\n",
    "    - Benefits\n",
    "    \"\"\"\n",
    "    \n",
    "    # GPT-4o-mini pricing\n",
    "    INPUT_PRICE_PER_1K = 0.000150\n",
    "    OUTPUT_PRICE_PER_1K = 0.000600\n",
    "    \n",
    "    def __init__(self, openai_api_key: str, model: str = \"gpt-4o-mini\"):\n",
    "        \"\"\"\n",
    "        Initialize job description extractor\n",
    "        \n",
    "        Args:\n",
    "            openai_api_key: Your OpenAI API key\n",
    "            model: OpenAI model to use\n",
    "        \"\"\"\n",
    "        self.client = OpenAI(api_key=openai_api_key)\n",
    "        self.model = model\n",
    "        self.schema = self._get_schema()\n",
    "        \n",
    "        # Metrics\n",
    "        self.api_calls = 0\n",
    "        self.input_tokens = 0\n",
    "        self.output_tokens = 0\n",
    "    \n",
    "    def _get_schema(self) -> dict:\n",
    "        \"\"\"JSON schema for structured job requirement extraction\"\"\"\n",
    "        return {\n",
    "            \"name\": \"job_requirements_extraction\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"job_title\": {\"type\": \"string\"},\n",
    "                    \"company\": {\"type\": \"string\"},\n",
    "                    \"job_type\": {\"type\": \"string\"},\n",
    "                    \"experience_level\": {\"type\": \"string\"},\n",
    "                    \"years_of_experience\": {\"type\": \"string\"},\n",
    "                    \"required_skills\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"preferred_skills\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"technical_requirements\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required_qualifications\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"preferred_qualifications\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"education\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"minimum_degree\": {\"type\": \"string\"},\n",
    "                            \"field_of_study\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\"type\": \"string\"}\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"minimum_degree\", \"field_of_study\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"certifications\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"responsibilities\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"key_responsibilities\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"salary_range\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"min\": {\"type\": \"string\"},\n",
    "                            \"max\": {\"type\": \"string\"},\n",
    "                            \"currency\": {\"type\": \"string\"},\n",
    "                            \"period\": {\"type\": \"string\"}\n",
    "                        },\n",
    "                        \"required\": [\"min\", \"max\", \"currency\", \"period\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"benefits\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"location\": {\"type\": \"string\"},\n",
    "                    \"remote_status\": {\"type\": \"string\"},\n",
    "                    \"languages\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"soft_skills\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"industry\": {\"type\": \"string\"},\n",
    "                    \"reporting_to\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"job_title\", \"company\", \"job_type\", \"experience_level\", \"years_of_experience\",\n",
    "                    \"required_skills\", \"preferred_skills\", \"technical_requirements\",\n",
    "                    \"required_qualifications\", \"preferred_qualifications\", \"education\", \n",
    "                    \"certifications\", \"responsibilities\", \"key_responsibilities\", \"salary_range\",\n",
    "                    \"benefits\", \"location\", \"remote_status\", \"languages\", \"soft_skills\",\n",
    "                    \"industry\", \"reporting_to\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def extract(self, job_description: str, verbose: bool = True) -> tuple[Dict[str, Any], ExtractionMetrics]:\n",
    "        \"\"\"\n",
    "        Extract structured requirements from job description\n",
    "        \n",
    "        Args:\n",
    "            job_description: Raw job description text\n",
    "            verbose: Print extraction progress\n",
    "            \n",
    "        Returns:\n",
    "            (extracted_data, metrics)\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"ðŸš€ Starting job requirement extraction...\")\n",
    "            print(f\"ðŸ“„ Model: {self.model}\\n\")\n",
    "        \n",
    "        # Reset metrics\n",
    "        self.api_calls = 0\n",
    "        self.input_tokens = 0\n",
    "        self.output_tokens = 0\n",
    "        \n",
    "        # Extract requirements\n",
    "        if verbose:\n",
    "            print(\"ðŸ“‹ Parsing job description...\")\n",
    "        \n",
    "        extracted_data = self._extract_requirements(job_description)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        cost = self._calculate_cost()\n",
    "        \n",
    "        metrics = ExtractionMetrics(\n",
    "            api_calls=self.api_calls,\n",
    "            input_tokens=self.input_tokens,\n",
    "            output_tokens=self.output_tokens,\n",
    "            cost_estimate=cost\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"âœ… Extraction complete!\\n\")\n",
    "            print(metrics)\n",
    "        \n",
    "        return extracted_data, metrics\n",
    "    \n",
    "    def _extract_requirements(self, job_description: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract requirements using GPT-4o-mini with structured output\"\"\"\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are an expert job description analyzer. Extract ALL job requirements and information from the provided job description.\n",
    "                \n",
    "Extract information systematically:\n",
    "- Identify required vs preferred skills and qualifications\n",
    "- Extract technical and soft skills\n",
    "- List key responsibilities\n",
    "- Identify education and certification requirements\n",
    "- Extract salary, benefits, and location info\n",
    "- Determine remote status and job type\n",
    "\n",
    "Use empty strings \"\" for missing text fields and empty arrays [] for missing lists.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Extract structured job requirements from this job description:\\n\\n{job_description}\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        response = llm.generate_json(\n",
    "            messages=messages,\n",
    "            model=self.model,\n",
    "            schema=self.schema\n",
    "        )\n",
    "        \n",
    "        # Track metrics\n",
    "        self.api_calls += 1\n",
    "        self.input_tokens += response.usage.prompt_tokens\n",
    "        self.output_tokens += response.usage.completion_tokens\n",
    "        \n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    \n",
    "    def extract_to_file(self, job_description: str, output_file: str, verbose: bool = True) -> None:\n",
    "        \"\"\"Extract and save results to JSON file\"\"\"\n",
    "        extracted_data, metrics = self.extract(job_description, verbose)\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(extracted_data, f, indent=2)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ðŸ’¾ Results saved to: {output_file}\\n\")\n",
    "    \n",
    "    def _calculate_cost(self) -> float:\n",
    "        \"\"\"Calculate estimated cost based on token usage\"\"\"\n",
    "        input_cost = (self.input_tokens / 1000) * self.INPUT_PRICE_PER_1K\n",
    "        output_cost = (self.output_tokens / 1000) * self.OUTPUT_PRICE_PER_1K\n",
    "        return input_cost + output_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "047d223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting job requirement extraction...\n",
      "ðŸ“„ Model: gpt-4o-mini\n",
      "\n",
      "ðŸ“‹ Parsing job description...\n",
      "âœ… Extraction complete!\n",
      "\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘      JOB EXTRACTION METRICS                  â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘ API Calls:           1        â•‘\n",
      "â•‘ Input Tokens:      641     â•‘\n",
      "â•‘ Output Tokens:     268    â•‘\n",
      "â•‘ Est. Cost:        $0.0003â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "{\n",
      "  \"job_title\": \"Senior Software Engineer\",\n",
      "  \"company\": \"TechCorp Inc.\",\n",
      "  \"job_type\": \"Remote\",\n",
      "  \"experience_level\": \"Senior\",\n",
      "  \"years_of_experience\": \"5+\",\n",
      "  \"required_skills\": [\n",
      "    \"Python\",\n",
      "    \"JavaScript\",\n",
      "    \"Go\",\n",
      "    \"Microservices architecture\",\n",
      "    \"AWS\",\n",
      "    \"Google Cloud Platform\",\n",
      "    \"PostgreSQL\",\n",
      "    \"Redis\",\n",
      "    \"Docker\",\n",
      "    \"Kubernetes\"\n",
      "  ],\n",
      "  \"preferred_skills\": [\n",
      "    \"ML/AI pipelines\",\n",
      "    \"GraphQL\",\n",
      "    \"Previous startup experience\",\n",
      "    \"Open source contributions\"\n",
      "  ],\n",
      "  \"technical_requirements\": [\n",
      "    \"Python\",\n",
      "    \"JavaScript\",\n",
      "    \"Go\",\n",
      "    \"Microservices architecture\",\n",
      "    \"AWS\",\n",
      "    \"Google Cloud Platform\",\n",
      "    \"PostgreSQL\",\n",
      "    \"Redis\",\n",
      "    \"Docker\",\n",
      "    \"Kubernetes\"\n",
      "  ],\n",
      "  \"required_qualifications\": [\n",
      "    \"Bachelor's degree in Computer Science or related field\"\n",
      "  ],\n",
      "  \"preferred_qualifications\": [],\n",
      "  \"education\": {\n",
      "    \"minimum_degree\": \"Bachelor's degree\",\n",
      "    \"field_of_study\": [\n",
      "      \"Computer Science\",\n",
      "      \"related field\"\n",
      "    ]\n",
      "  },\n",
      "  \"certifications\": [],\n",
      "  \"responsibilities\": [\n",
      "    \"Design and implement scalable backend systems\",\n",
      "    \"Code reviews and mentoring junior engineers\",\n",
      "    \"Participate in architectural decisions\",\n",
      "    \"Collaborate with product and design teams\"\n",
      "  ],\n",
      "  \"key_responsibilities\": [],\n",
      "  \"salary_range\": {\n",
      "    \"min\": \"150000\",\n",
      "    \"max\": \"200000\",\n",
      "    \"currency\": \"USD\",\n",
      "    \"period\": \"year\"\n",
      "  },\n",
      "  \"benefits\": [\n",
      "    \"Health insurance\",\n",
      "    \"401(k) matching\",\n",
      "    \"Unlimited PTO\",\n",
      "    \"Home office stipend\"\n",
      "  ],\n",
      "  \"location\": \"\",\n",
      "  \"remote_status\": \"Remote\",\n",
      "  \"languages\": [],\n",
      "  \"soft_skills\": [],\n",
      "  \"industry\": \"\",\n",
      "  \"reporting_to\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "extractor = JobDescriptionExtractor(openai_api_key=API_KEY)\n",
    "\n",
    "# Sample job description\n",
    "sample_job = \"\"\"\n",
    "Senior Software Engineer - Remote\n",
    "Company: TechCorp Inc.\n",
    "\n",
    "About the Role:\n",
    "We're looking for a Senior Software Engineer to join our platform team. You'll architect scalable systems \n",
    "and mentor junior developers while working on cutting-edge technologies.\n",
    "\n",
    "Requirements:\n",
    "- 5+ years of software development experience\n",
    "- Expert-level proficiency in Python, JavaScript, and Go\n",
    "- Strong experience with microservices architecture\n",
    "- AWS or Google Cloud Platform experience required\n",
    "- PostgreSQL and Redis expertise\n",
    "- Docker and Kubernetes knowledge\n",
    "\n",
    "Nice to Have:\n",
    "- Experience with ML/AI pipelines\n",
    "- GraphQL expertise\n",
    "- Previous startup experience\n",
    "- Open source contributions\n",
    "\n",
    "Responsibilities:\n",
    "- Design and implement scalable backend systems\n",
    "- Code reviews and mentoring junior engineers\n",
    "- Participate in architectural decisions\n",
    "- Collaborate with product and design teams\n",
    "\n",
    "Education:\n",
    "- Bachelor's degree in Computer Science or related field\n",
    "\n",
    "Benefits:\n",
    "- $150,000 - $200,000 salary\n",
    "- Health insurance, 401(k) matching\n",
    "- Unlimited PTO\n",
    "- Home office stipend\n",
    "\"\"\"\n",
    "\n",
    "# Extract requirements\n",
    "result, metrics = extractor.extract(sample_job)\n",
    "\n",
    "# Print results\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d82bea9",
   "metadata": {},
   "source": [
    "# Question Generation Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7354b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any, List, Literal, Optional\n",
    "from openai import OpenAI\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class QuestionSource(Enum):\n",
    "    \"\"\"Question source types\"\"\"\n",
    "    CLIENT_PROVIDED = \"client_provided\"\n",
    "    AI_GENERATED = \"ai_generated\"\n",
    "    HYBRID = \"hybrid\"\n",
    "\n",
    "\n",
    "class DifficultyLevel(Enum):\n",
    "    \"\"\"Difficulty levels for interview questions\"\"\"\n",
    "    EASY = \"easy\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HARD = \"hard\"\n",
    "\n",
    "\n",
    "class InterviewPhase(Enum):\n",
    "    \"\"\"Interview phases\"\"\"\n",
    "    FIRST = \"first_round\"\n",
    "    SECOND = \"second_round\"\n",
    "    FINAL = \"final_round\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InterviewConfig:\n",
    "    \"\"\"Configuration for interview question generation\"\"\"\n",
    "    phase: InterviewPhase\n",
    "    difficulty_level: DifficultyLevel\n",
    "    question_source: QuestionSource\n",
    "    interview_duration_minutes: int  # Changed from total_questions\n",
    "    question_length: Literal[\"short\", \"medium\", \"long\"]\n",
    "    client_questions: List[str] = None\n",
    "    client_questions_count: int = 0  # Only used if HYBRID mode\n",
    "    buffer_time_percent: float = 0.15  # 15% buffer for transitions, rapport building\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.client_questions is None:\n",
    "            self.client_questions = []\n",
    "        if self.question_source == QuestionSource.HYBRID and not self.client_questions:\n",
    "            raise ValueError(\"Client questions required for HYBRID mode\")\n",
    "        \n",
    "        # Calculate number of questions based on time\n",
    "        self.total_questions = self._calculate_question_count()\n",
    "    \n",
    "    def _calculate_question_count(self) -> int:\n",
    "        \"\"\"Calculate how many questions fit in the given time\"\"\"\n",
    "        # Answer time per question (in minutes)\n",
    "        answer_times = {\n",
    "            \"short\": 2,    # 1-2 minutes\n",
    "            \"medium\": 4,   # 3-5 minutes\n",
    "            \"long\": 7      # 5-10 minutes\n",
    "        }\n",
    "        \n",
    "        # Add 1 minute per question for asking the question + brief discussion\n",
    "        time_per_question = answer_times[self.question_length] + 1\n",
    "        \n",
    "        # Apply buffer (e.g., 15% for intro, transitions, wrap-up)\n",
    "        available_time = self.interview_duration_minutes * (1 - self.buffer_time_percent)\n",
    "        \n",
    "        # Calculate questions\n",
    "        question_count = int(available_time / time_per_question)\n",
    "        \n",
    "        # Ensure at least 1 question\n",
    "        return max(1, question_count)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InterviewMetrics:\n",
    "    \"\"\"Metrics for interview generation\"\"\"\n",
    "    api_calls: int\n",
    "    input_tokens: int\n",
    "    output_tokens: int\n",
    "    cost_estimate: float\n",
    "    questions_generated: int\n",
    "    interview_duration_minutes: int\n",
    "    estimated_actual_duration_minutes: int\n",
    "    buffer_time_minutes: float\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘      INTERVIEW GENERATION METRICS                  â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ Target Duration:      {self.interview_duration_minutes:>3} minutes            â•‘\n",
    "â•‘ Estimated Actual:     {self.estimated_actual_duration_minutes:>3} minutes            â•‘\n",
    "â•‘ Buffer Time:          {self.buffer_time_minutes:>3.1f} minutes            â•‘\n",
    "â•‘ Questions Generated:  {self.questions_generated:>3}                    â•‘\n",
    "â•‘                                                    â•‘\n",
    "â•‘ API Calls:            {self.api_calls:>4}                   â•‘\n",
    "â•‘ Input Tokens:         {self.input_tokens:>6}                 â•‘\n",
    "â•‘ Output Tokens:        {self.output_tokens:>6}                 â•‘\n",
    "â•‘ Est. Cost:            ${self.cost_estimate:>7.4f}              â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class InterviewQuestionGenerator:\n",
    "    \"\"\"\n",
    "    Generate customized interview questions based on TIME DURATION:\n",
    "    - Specify interview duration (e.g., 10, 30, 60 minutes)\n",
    "    - System automatically calculates optimal number of questions\n",
    "    - Accounts for answer length, transitions, and buffer time\n",
    "    \"\"\"\n",
    "    \n",
    "    INPUT_PRICE_PER_1K = 0.000150\n",
    "    OUTPUT_PRICE_PER_1K = 0.000600\n",
    "    \n",
    "    def __init__(self, openai_api_key: str, model: str = \"gpt-4o-mini\"):\n",
    "        self.client = OpenAI(api_key=openai_api_key)\n",
    "        self.model = model\n",
    "        self.schema = self._get_schema()\n",
    "        \n",
    "        # Metrics\n",
    "        self.api_calls = 0\n",
    "        self.input_tokens = 0\n",
    "        self.output_tokens = 0\n",
    "    \n",
    "    def _get_schema(self) -> dict:\n",
    "        \"\"\"JSON schema for interview questions\"\"\"\n",
    "        return {\n",
    "            \"name\": \"interview_questions_generation\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"questions\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"question_id\": {\"type\": \"integer\"},\n",
    "                                \"question\": {\"type\": \"string\"},\n",
    "                                \"category\": {\"type\": \"string\"},\n",
    "                                \"difficulty\": {\"type\": \"string\"},\n",
    "                                \"expected_answer_type\": {\"type\": \"string\"},\n",
    "                                \"estimated_time_minutes\": {\"type\": \"integer\"},\n",
    "                                \"key_points\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"follow_up_questions\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"why_asked\": {\"type\": \"string\"},\n",
    "                                \"relevance_to_cv\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"required\": [\n",
    "                                \"question_id\", \"question\", \"category\", \"difficulty\",\n",
    "                                \"expected_answer_type\", \"estimated_time_minutes\",\n",
    "                                \"key_points\", \"follow_up_questions\",\n",
    "                                \"why_asked\", \"relevance_to_cv\"\n",
    "                            ],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    },\n",
    "                    \"interview_summary\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"total_questions\": {\"type\": \"integer\"},\n",
    "                            \"difficulty_distribution\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"easy\": {\"type\": \"integer\"},\n",
    "                                    \"medium\": {\"type\": \"integer\"},\n",
    "                                    \"hard\": {\"type\": \"integer\"}\n",
    "                                },\n",
    "                                \"required\": [\"easy\", \"medium\", \"hard\"],\n",
    "                                \"additionalProperties\": False\n",
    "                            },\n",
    "                            \"question_categories\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"estimated_interview_duration_minutes\": {\"type\": \"integer\"}\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"total_questions\", \"difficulty_distribution\",\n",
    "                            \"question_categories\", \"estimated_interview_duration_minutes\"\n",
    "                        ],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"questions\", \"interview_summary\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def generate(\n",
    "        self,\n",
    "        job_requirements: Dict[str, Any],\n",
    "        candidate_cv: Dict[str, Any],\n",
    "        config: InterviewConfig,\n",
    "        verbose: bool = True\n",
    "    ) -> tuple[Dict[str, Any], InterviewMetrics]:\n",
    "        \"\"\"\n",
    "        Generate interview questions based on time duration\n",
    "        \n",
    "        Args:\n",
    "            job_requirements: Extracted job requirements JSON\n",
    "            candidate_cv: Extracted resume data JSON\n",
    "            config: InterviewConfig with TIME-BASED parameters\n",
    "            verbose: Print progress\n",
    "            \n",
    "        Returns:\n",
    "            (generated_questions, metrics)\n",
    "        \"\"\"\n",
    "        self.api_calls = 0\n",
    "        self.input_tokens = 0\n",
    "        self.output_tokens = 0\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"ðŸš€ Starting TIME-BASED interview question generation...\")\n",
    "            print(f\"â±ï¸  Interview Duration: {config.interview_duration_minutes} minutes\")\n",
    "            print(f\"ðŸ“Š Calculated Questions: {config.total_questions}\")\n",
    "            print(f\"ðŸ“„ Model: {self.model}\")\n",
    "            print(f\"ðŸŽ¯ Configuration: {config.phase.value} - {config.difficulty_level.value}\")\n",
    "            print(f\"ðŸ“Š Source: {config.question_source.value}\")\n",
    "            print(f\"â³ Answer Length: {config.question_length}\\n\")\n",
    "        \n",
    "        # Build prompt based on source type\n",
    "        if config.question_source == QuestionSource.CLIENT_PROVIDED:\n",
    "            if verbose:\n",
    "                print(\"âœ“ Using client-provided questions only\")\n",
    "            questions = self._format_client_questions(config.client_questions, config)\n",
    "        \n",
    "        elif config.question_source == QuestionSource.AI_GENERATED:\n",
    "            if verbose:\n",
    "                print(\"ðŸ¤– Generating all questions with AI...\")\n",
    "            questions = self._generate_ai_questions(\n",
    "                job_requirements, candidate_cv, config, verbose\n",
    "            )\n",
    "        \n",
    "        else:  # HYBRID\n",
    "            if verbose:\n",
    "                print(f\"ðŸ”„ Using hybrid approach: {config.client_questions_count} client + \"\n",
    "                      f\"{config.total_questions - config.client_questions_count} AI questions\")\n",
    "            questions = self._generate_hybrid_questions(\n",
    "                job_requirements, candidate_cv, config, verbose\n",
    "            )\n",
    "        \n",
    "        # Calculate metrics\n",
    "        cost = self._calculate_cost()\n",
    "        buffer_time = config.interview_duration_minutes * config.buffer_time_percent\n",
    "        \n",
    "        metrics = InterviewMetrics(\n",
    "            api_calls=self.api_calls,\n",
    "            input_tokens=self.input_tokens,\n",
    "            output_tokens=self.output_tokens,\n",
    "            cost_estimate=cost,\n",
    "            questions_generated=len(questions.get(\"questions\", [])),\n",
    "            interview_duration_minutes=config.interview_duration_minutes,\n",
    "            estimated_actual_duration_minutes=questions[\"interview_summary\"][\"estimated_interview_duration_minutes\"],\n",
    "            buffer_time_minutes=buffer_time\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nâœ… Interview generation complete!\\n\")\n",
    "            print(metrics)\n",
    "        \n",
    "        return questions, metrics\n",
    "    \n",
    "    def _format_client_questions(self, questions: List[str], config: InterviewConfig) -> Dict[str, Any]:\n",
    "        \"\"\"Format client-provided questions with time estimates\"\"\"\n",
    "        answer_times = {\"short\": 2, \"medium\": 4, \"long\": 7}\n",
    "        time_per_q = answer_times[config.question_length] + 1  # +1 for asking\n",
    "        \n",
    "        formatted_questions = []\n",
    "        for idx, question in enumerate(questions[:config.total_questions], 1):\n",
    "            formatted_questions.append({\n",
    "                \"question_id\": idx,\n",
    "                \"question\": question,\n",
    "                \"category\": \"Client-Provided\",\n",
    "                \"difficulty\": config.difficulty_level.value,\n",
    "                \"expected_answer_type\": config.question_length,\n",
    "                \"estimated_time_minutes\": time_per_q,\n",
    "                \"key_points\": [],\n",
    "                \"follow_up_questions\": [],\n",
    "                \"why_asked\": \"Provided by client\",\n",
    "                \"relevance_to_cv\": \"To be determined during interview\"\n",
    "            })\n",
    "        \n",
    "        total_time = len(formatted_questions) * time_per_q\n",
    "        \n",
    "        return {\n",
    "            \"questions\": formatted_questions,\n",
    "            \"interview_summary\": {\n",
    "                \"total_questions\": len(formatted_questions),\n",
    "                \"difficulty_distribution\": {\n",
    "                    \"easy\": len([q for q in formatted_questions if config.difficulty_level == DifficultyLevel.EASY]),\n",
    "                    \"medium\": len([q for q in formatted_questions if config.difficulty_level == DifficultyLevel.MEDIUM]),\n",
    "                    \"hard\": len([q for q in formatted_questions if config.difficulty_level == DifficultyLevel.HARD])\n",
    "                },\n",
    "                \"question_categories\": [\"Client-Provided\"],\n",
    "                \"estimated_interview_duration_minutes\": total_time\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_ai_questions(\n",
    "        self,\n",
    "        job_requirements: Dict[str, Any],\n",
    "        candidate_cv: Dict[str, Any],\n",
    "        config: InterviewConfig,\n",
    "        verbose: bool\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Generate all questions using AI\"\"\"\n",
    "        prompt = self._build_generation_prompt(\n",
    "            job_requirements, candidate_cv, config, all_ai=True\n",
    "        )\n",
    "        return self._call_api(prompt)\n",
    "    \n",
    "    def _generate_hybrid_questions(\n",
    "        self,\n",
    "        job_requirements: Dict[str, Any],\n",
    "        candidate_cv: Dict[str, Any],\n",
    "        config: InterviewConfig,\n",
    "        verbose: bool\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Generate hybrid questions (client + AI)\"\"\"\n",
    "        client_qs_section = f\"\"\"\n",
    "CLIENT PROVIDED QUESTIONS (Must include these):\n",
    "{json.dumps(config.client_questions, indent=2)}\n",
    "\n",
    "Include these {config.client_questions_count} questions as-is, then generate {config.total_questions - config.client_questions_count} additional AI questions.\n",
    "\"\"\"\n",
    "        \n",
    "        prompt = self._build_generation_prompt(\n",
    "            job_requirements, candidate_cv, config, all_ai=False,\n",
    "            client_questions_section=client_qs_section\n",
    "        )\n",
    "        return self._call_api(prompt)\n",
    "    \n",
    "    def _build_generation_prompt(\n",
    "        self,\n",
    "        job_requirements: Dict[str, Any],\n",
    "        candidate_cv: Dict[str, Any],\n",
    "        config: InterviewConfig,\n",
    "        all_ai: bool = True,\n",
    "        client_questions_section: str = \"\"\n",
    "    ) -> str:\n",
    "        \"\"\"Build the prompt for question generation\"\"\"\n",
    "        \n",
    "        phase_descriptions = {\n",
    "            InterviewPhase.FIRST: \"screening round - focus on basic fit and foundational skills\",\n",
    "            InterviewPhase.SECOND: \"technical round - dive deep into technical expertise and problem-solving\",\n",
    "            InterviewPhase.FINAL: \"executive/final round - assess culture fit, leadership, and final suitability\"\n",
    "        }\n",
    "        \n",
    "        answer_length_guidance = {\n",
    "            \"short\": \"1-2 minute answers expected\",\n",
    "            \"medium\": \"3-5 minute answers expected\",\n",
    "            \"long\": \"5-10 minute answers expected\"\n",
    "        }\n",
    "        \n",
    "        time_per_question = {\n",
    "            \"short\": 3,   # 2 min answer + 1 min asking/transition\n",
    "            \"medium\": 5,  # 4 min answer + 1 min asking/transition\n",
    "            \"long\": 8     # 7 min answer + 1 min asking/transition\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"You are an expert interview panel coordinator. Generate interview questions for a {config.interview_duration_minutes}-minute interview.\n",
    "\n",
    "TIME CONSTRAINTS:\n",
    "- Total Interview Duration: {config.interview_duration_minutes} minutes\n",
    "- Questions to Generate: {config.total_questions}\n",
    "- Time per Question: ~{time_per_question[config.question_length]} minutes (including answer + asking)\n",
    "- Buffer Time: {config.buffer_time_percent * 100}% for intro, transitions, wrap-up\n",
    "\n",
    "INTERVIEW CONTEXT:\n",
    "- Phase: {config.phase.value} ({phase_descriptions[config.phase]})\n",
    "- Difficulty: {config.difficulty_level.value}\n",
    "- Answer Length: {answer_length_guidance[config.question_length]}\n",
    "- Question Source: {config.question_source.value}\n",
    "\n",
    "JOB REQUIREMENTS:\n",
    "{json.dumps(job_requirements, indent=2)}\n",
    "\n",
    "CANDIDATE PROFILE:\n",
    "{json.dumps(candidate_cv, indent=2)}\n",
    "\n",
    "{client_questions_section}\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Generate EXACTLY {config.total_questions} questions (optimized for {config.interview_duration_minutes} minutes)\n",
    "2. Each question should have estimated_time_minutes set to {time_per_question[config.question_length]}\n",
    "3. Tailor questions to match the candidate's experience and the job role\n",
    "4. For {config.phase.value}, adjust question depth and scope appropriately\n",
    "5. Include follow-up questions for each main question\n",
    "6. Provide key points that indicate a good answer\n",
    "7. Explain why each question is relevant to this role\n",
    "8. Reference the candidate's CV when relevant\n",
    "9. Ensure difficulty level is consistent: {config.difficulty_level.value}\n",
    "10. Mix question types: technical, behavioral, situational, problem-solving\n",
    "11. Questions should expose gaps or strengths relative to job requirements\n",
    "12. Prioritize most important questions first (in case interview runs short)\n",
    "\n",
    "GENERATE {config.total_questions} TIME-OPTIMIZED INTERVIEW QUESTIONS.\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def _call_api(self, prompt: str) -> Dict[str, Any]:\n",
    "        \"\"\"Call OpenAI API with schema validation\"\"\"\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert interview question generator. Generate comprehensive, time-optimized interview questions with detailed follow-ups and evaluation criteria.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        response = llm.generate_json(\n",
    "            messages=messages,\n",
    "            model=self.model,\n",
    "            schema=self.schema\n",
    "        )\n",
    "        # Track metrics\n",
    "        self.api_calls += 1\n",
    "        self.input_tokens += response.usage.prompt_tokens\n",
    "        self.output_tokens += response.usage.completion_tokens\n",
    "        \n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    \n",
    "    def save_to_file(self, questions: Dict[str, Any], output_file: str, verbose: bool = True) -> None:\n",
    "        \"\"\"Save generated questions to JSON file\"\"\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(questions, f, indent=2)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ðŸ’¾ Questions saved to: {output_file}\\n\")\n",
    "    \n",
    "    def _calculate_cost(self) -> float:\n",
    "        \"\"\"Calculate estimated cost\"\"\"\n",
    "        input_cost = (self.input_tokens / 1000) * self.INPUT_PRICE_PER_1K\n",
    "        output_cost = (self.output_tokens / 1000) * self.OUTPUT_PRICE_PER_1K\n",
    "        return input_cost + output_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3ebd7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SCENARIO 1: 10-minute quick screening interview\n",
      "============================================================\n",
      "ðŸš€ Starting TIME-BASED interview question generation...\n",
      "â±ï¸  Interview Duration: 10 minutes\n",
      "ðŸ“Š Calculated Questions: 2\n",
      "ðŸ“„ Model: gpt-4o-mini\n",
      "ðŸŽ¯ Configuration: first_round - easy\n",
      "ðŸ“Š Source: ai_generated\n",
      "â³ Answer Length: short\n",
      "\n",
      "ðŸ¤– Generating all questions with AI...\n",
      "\n",
      "âœ… Interview generation complete!\n",
      "\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘      INTERVIEW GENERATION METRICS                  â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘ Target Duration:       10 minutes            â•‘\n",
      "â•‘ Estimated Actual:      10 minutes            â•‘\n",
      "â•‘ Buffer Time:          1.5 minutes            â•‘\n",
      "â•‘ Questions Generated:    2                    â•‘\n",
      "â•‘                                                    â•‘\n",
      "â•‘ API Calls:               1                   â•‘\n",
      "â•‘ Input Tokens:            678                 â•‘\n",
      "â•‘ Output Tokens:           430                 â•‘\n",
      "â•‘ Est. Cost:            $ 0.0004              â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "\n",
      "============================================================\n",
      "SCENARIO 2: 30-minute technical deep-dive\n",
      "============================================================\n",
      "ðŸš€ Starting TIME-BASED interview question generation...\n",
      "â±ï¸  Interview Duration: 30 minutes\n",
      "ðŸ“Š Calculated Questions: 5\n",
      "ðŸ“„ Model: gpt-4o-mini\n",
      "ðŸŽ¯ Configuration: second_round - hard\n",
      "ðŸ“Š Source: ai_generated\n",
      "â³ Answer Length: medium\n",
      "\n",
      "ðŸ¤– Generating all questions with AI...\n",
      "\n",
      "âœ… Interview generation complete!\n",
      "\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘      INTERVIEW GENERATION METRICS                  â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘ Target Duration:       30 minutes            â•‘\n",
      "â•‘ Estimated Actual:      30 minutes            â•‘\n",
      "â•‘ Buffer Time:          4.5 minutes            â•‘\n",
      "â•‘ Questions Generated:    5                    â•‘\n",
      "â•‘                                                    â•‘\n",
      "â•‘ API Calls:               1                   â•‘\n",
      "â•‘ Input Tokens:            678                 â•‘\n",
      "â•‘ Output Tokens:           832                 â•‘\n",
      "â•‘ Est. Cost:            $ 0.0006              â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "\n",
      "============================================================\n",
      "SCENARIO 3: 60-minute final round with hybrid questions\n",
      "============================================================\n",
      "ðŸš€ Starting TIME-BASED interview question generation...\n",
      "â±ï¸  Interview Duration: 60 minutes\n",
      "ðŸ“Š Calculated Questions: 6\n",
      "ðŸ“„ Model: gpt-4o-mini\n",
      "ðŸŽ¯ Configuration: final_round - medium\n",
      "ðŸ“Š Source: hybrid\n",
      "â³ Answer Length: long\n",
      "\n",
      "ðŸ”„ Using hybrid approach: 2 client + 4 AI questions\n",
      "\n",
      "âœ… Interview generation complete!\n",
      "\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘      INTERVIEW GENERATION METRICS                  â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘ Target Duration:       60 minutes            â•‘\n",
      "â•‘ Estimated Actual:      60 minutes            â•‘\n",
      "â•‘ Buffer Time:          9.0 minutes            â•‘\n",
      "â•‘ Questions Generated:    6                    â•‘\n",
      "â•‘                                                    â•‘\n",
      "â•‘ API Calls:               1                   â•‘\n",
      "â•‘ Input Tokens:            730                 â•‘\n",
      "â•‘ Output Tokens:           975                 â•‘\n",
      "â•‘ Est. Cost:            $ 0.0007              â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ðŸ’¾ Questions saved to: interview_10min.json\n",
      "\n",
      "ðŸ’¾ Questions saved to: interview_30min.json\n",
      "\n",
      "ðŸ’¾ Questions saved to: interview_60min.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "#                           EXAMPLE USAGE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    generator = InterviewQuestionGenerator(openai_api_key=API_KEY)\n",
    "    \n",
    "    # Sample data\n",
    "    job_requirements = {\n",
    "        \"job_title\": \"Senior Software Engineer\",\n",
    "        \"required_skills\": [\"Python\", \"JavaScript\", \"Go\", \"microservices\", \"AWS\", \"Docker\"],\n",
    "        \"experience_required\": \"5+ years\"\n",
    "    }\n",
    "    \n",
    "    candidate_cv = {\n",
    "        \"personal_info\": {\"full_name\": \"Faizan Munsaf\"},\n",
    "        \"skills\": [\"Python\", \"FastAPI\", \"Django\", \"Machine Learning\"],\n",
    "        \"experience\": [{\"company\": \"Software Alliance\", \"position\": \"ML Engineer & FullStack Developer\"}]\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"SCENARIO 1: 10-minute quick screening interview\")\n",
    "    print(\"=\" * 60)\n",
    "    config1 = InterviewConfig(\n",
    "        phase=InterviewPhase.FIRST,\n",
    "        difficulty_level=DifficultyLevel.EASY,\n",
    "        question_source=QuestionSource.AI_GENERATED,\n",
    "        interview_duration_minutes=10,\n",
    "        question_length=\"short\"  # Will generate ~3 questions\n",
    "    )\n",
    "    \n",
    "    questions1, metrics1 = generator.generate(job_requirements, candidate_cv, config1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SCENARIO 2: 30-minute technical deep-dive\")\n",
    "    print(\"=\" * 60)\n",
    "    config2 = InterviewConfig(\n",
    "        phase=InterviewPhase.SECOND,\n",
    "        difficulty_level=DifficultyLevel.HARD,\n",
    "        question_source=QuestionSource.AI_GENERATED,\n",
    "        interview_duration_minutes=30,\n",
    "        question_length=\"medium\"  # Will generate ~5 questions\n",
    "    )\n",
    "    \n",
    "    questions2, metrics2 = generator.generate(job_requirements, candidate_cv, config2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SCENARIO 3: 60-minute final round with hybrid questions\")\n",
    "    print(\"=\" * 60)\n",
    "    config3 = InterviewConfig(\n",
    "        phase=InterviewPhase.FINAL,\n",
    "        difficulty_level=DifficultyLevel.MEDIUM,\n",
    "        question_source=QuestionSource.HYBRID,\n",
    "        interview_duration_minutes=60,\n",
    "        question_length=\"long\",  # Will generate ~6 total questions\n",
    "        client_questions=[\n",
    "            \"Tell us about yourself and your career journey\",\n",
    "            \"Where do you see yourself in 5 years?\"\n",
    "        ],\n",
    "        client_questions_count=2  # 2 client + 4 AI = 6 total\n",
    "    )\n",
    "    \n",
    "    questions3, metrics3 = generator.generate(job_requirements, candidate_cv, config3)\n",
    "    \n",
    "    # Save results\n",
    "    generator.save_to_file(questions1, \"interview_10min.json\")\n",
    "    generator.save_to_file(questions2, \"interview_30min.json\")\n",
    "    generator.save_to_file(questions3, \"interview_60min.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c00de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': [{'question_id': 1,\n",
       "   'question': 'Tell us about yourself and your career journey.',\n",
       "   'category': 'Behavioral',\n",
       "   'difficulty': 'medium',\n",
       "   'expected_answer_type': 'narrative',\n",
       "   'estimated_time_minutes': 8,\n",
       "   'key_points': ['Clarity in career transitions',\n",
       "    'Key achievements and milestones',\n",
       "    'Connection to the role'],\n",
       "   'follow_up_questions': ['What motivated you to choose a career in software engineering?',\n",
       "    'Could you elaborate on a project that significantly impacted your career?'],\n",
       "   'why_asked': \"This question helps understand the candidate's background, motivations, and how their experiences have shaped their professional identity.\",\n",
       "   'relevance_to_cv': \"The candidate's experience as an ML Engineer & FullStack Developer at Software Alliance ties directly to their qualifications for the Senior Software Engineer role.\"},\n",
       "  {'question_id': 2,\n",
       "   'question': 'Where do you see yourself in 5 years?',\n",
       "   'category': 'Career Aspirations',\n",
       "   'difficulty': 'medium',\n",
       "   'expected_answer_type': 'aspirational',\n",
       "   'estimated_time_minutes': 8,\n",
       "   'key_points': ['Alignment with company growth',\n",
       "    'Specific roles or skill development',\n",
       "    'Leadership aspirations'],\n",
       "   'follow_up_questions': [\"What steps do you think you'll take to achieve these goals?\",\n",
       "    'How do you see your goals impacting the team you work with?'],\n",
       "   'why_asked': \"Evaluating long-term goals helps gauge the candidate's commitment and cultural fit with the organization's growth trajectory.\",\n",
       "   'relevance_to_cv': 'His aspiration in software engineering will reflect his motivation to grow within the technology domain.'},\n",
       "  {'question_id': 3,\n",
       "   'question': 'Given your experience with Python, can you discuss a challenging project where you utilized Python to solve a complex problem?',\n",
       "   'category': 'Technical',\n",
       "   'difficulty': 'medium',\n",
       "   'expected_answer_type': 'problem-solving',\n",
       "   'estimated_time_minutes': 8,\n",
       "   'key_points': ['Description of project complexity',\n",
       "    'Use of Python and relevant libraries',\n",
       "    'Impact of the solution'],\n",
       "   'follow_up_questions': ['What difficulties did you encounter during this project, and how did you overcome them?',\n",
       "    'If you were to improve that project now, what would you change?'],\n",
       "   'why_asked': 'This question assesses technical proficiency in Python, critical for the role, and the ability to apply skills in real-world scenarios.',\n",
       "   'relevance_to_cv': \"The candidate's experience suggests proficiency in Python but needs to delve into practical application.\"},\n",
       "  {'question_id': 4,\n",
       "   'question': 'Can you describe an experience where you had to lead a team to deliver a software project? What challenges did you face?',\n",
       "   'category': 'Leadership',\n",
       "   'difficulty': 'medium',\n",
       "   'expected_answer_type': 'narrative',\n",
       "   'estimated_time_minutes': 8,\n",
       "   'key_points': ['Leadership approach',\n",
       "    'Conflict management',\n",
       "    'Final outcomes of the project'],\n",
       "   'follow_up_questions': ['How did you ensure that all team members were on the same page?',\n",
       "    'What tools or methodologies did you use for project management?'],\n",
       "   'why_asked': 'Leadership is key for a senior role, and this question evaluates both skills and experiences related to team management and delivery.',\n",
       "   'relevance_to_cv': \"The candidate's role likely involved collaboration in software development; this will provide insights into their leadership style.\"},\n",
       "  {'question_id': 5,\n",
       "   'question': 'Imagine that your microservices architecture is experiencing performance issues. How would you go about diagnosing and resolving them?',\n",
       "   'category': 'Problem-Solving',\n",
       "   'difficulty': 'medium',\n",
       "   'expected_answer_type': 'analytical',\n",
       "   'estimated_time_minutes': 8,\n",
       "   'key_points': ['Systematic approach to diagnostics',\n",
       "    'Tools or metrics to use',\n",
       "    'Proposed solutions'],\n",
       "   'follow_up_questions': ['What are the potential impacts of these performance issues on business operations?',\n",
       "    'How do you prioritize which issues to tackle first?'],\n",
       "   'why_asked': 'This evaluates critical thinking, analytical skills, and knowledge of microservices, which are essential for the role.',\n",
       "   'relevance_to_cv': \"The candidate's experience with microservices will be critical in understanding their approach to system-wide issues.\"},\n",
       "  {'question_id': 6,\n",
       "   'question': 'In your opinion, what are the key differences between traditional software development approaches and Agile methodologies? How have you applied Agile principles in your previous roles?',\n",
       "   'category': 'Situational',\n",
       "   'difficulty': 'medium',\n",
       "   'expected_answer_type': 'conceptual',\n",
       "   'estimated_time_minutes': 8,\n",
       "   'key_points': ['Clear understanding of Agile principles',\n",
       "    'Examples of Agile applied in a team',\n",
       "    'Impact on project delivery'],\n",
       "   'follow_up_questions': ['Can you give a specific example of a challenge you faced using Agile?',\n",
       "    'How do you handle team dynamics in an Agile environment?'],\n",
       "   'why_asked': 'Understanding Agile is crucial for modern software development, and this question tests the candidateâ€™s adaptability to team processes.',\n",
       "   'relevance_to_cv': \"Faizan's past roles may have required adaptability to team methodologies, making this relevant to collaboration and project success.\"}],\n",
       " 'interview_summary': {'total_questions': 6,\n",
       "  'difficulty_distribution': {'easy': 0, 'medium': 6, 'hard': 0},\n",
       "  'question_categories': ['Behavioral',\n",
       "   'Career Aspirations',\n",
       "   'Technical',\n",
       "   'Leadership',\n",
       "   'Problem-Solving',\n",
       "   'Situational'],\n",
       "  'estimated_interview_duration_minutes': 60}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "questions3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e249283",
   "metadata": {},
   "source": [
    "# Question Generation After Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1632db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_dict = {'questions': [{'question_id': 1,\n",
    "   'question': 'Tell us about yourself and your career journey.',\n",
    "   'category': 'Behavioral',\n",
    "   'difficulty': 'medium',\n",
    "   'expected_answer_type': 'narrative',\n",
    "   'estimated_time_minutes': 8,\n",
    "   'key_points': ['Clarity in career transitions',\n",
    "    'Key achievements and milestones',\n",
    "    'Connection to the role'],\n",
    "   'follow_up_questions': ['What motivated you to choose a career in software engineering?',\n",
    "    'Could you elaborate on a project that significantly impacted your career?'],\n",
    "   'why_asked': \"This question helps understand the candidate's background, motivations, and how their experiences have shaped their professional identity.\",\n",
    "   'relevance_to_cv': \"The candidate's experience as an ML Engineer & FullStack Developer at Software Alliance ties directly to their qualifications for the Senior Software Engineer role.\"},\n",
    "  {'question_id': 2,\n",
    "   'question': 'Where do you see yourself in 5 years?',\n",
    "   'category': 'Career Aspirations',\n",
    "   'difficulty': 'medium',\n",
    "   'expected_answer_type': 'aspirational',\n",
    "   'estimated_time_minutes': 8,\n",
    "   'key_points': ['Alignment with company growth',\n",
    "    'Specific roles or skill development',\n",
    "    'Leadership aspirations'],\n",
    "   'follow_up_questions': [\"What steps do you think you'll take to achieve these goals?\",\n",
    "    'How do you see your goals impacting the team you work with?'],\n",
    "   'why_asked': \"Evaluating long-term goals helps gauge the candidate's commitment and cultural fit with the organization's growth trajectory.\",\n",
    "   'relevance_to_cv': 'His aspiration in software engineering will reflect his motivation to grow within the technology domain.'},\n",
    "  {'question_id': 3,\n",
    "   'question': 'Given your experience with Python, can you discuss a challenging project where you utilized Python to solve a complex problem?',\n",
    "   'category': 'Technical',\n",
    "   'difficulty': 'medium',\n",
    "   'expected_answer_type': 'problem-solving',\n",
    "   'estimated_time_minutes': 8,\n",
    "   'key_points': ['Description of project complexity',\n",
    "    'Use of Python and relevant libraries',\n",
    "    'Impact of the solution'],\n",
    "   'follow_up_questions': ['What difficulties did you encounter during this project, and how did you overcome them?',\n",
    "    'If you were to improve that project now, what would you change?'],\n",
    "   'why_asked': 'This question assesses technical proficiency in Python, critical for the role, and the ability to apply skills in real-world scenarios.',\n",
    "   'relevance_to_cv': \"The candidate's experience suggests proficiency in Python but needs to delve into practical application.\"},\n",
    "  {'question_id': 4,\n",
    "   'question': 'Can you describe an experience where you had to lead a team to deliver a software project? What challenges did you face?',\n",
    "   'category': 'Leadership',\n",
    "   'difficulty': 'medium',\n",
    "   'expected_answer_type': 'narrative',\n",
    "   'estimated_time_minutes': 8,\n",
    "   'key_points': ['Leadership approach',\n",
    "    'Conflict management',\n",
    "    'Final outcomes of the project'],\n",
    "   'follow_up_questions': ['How did you ensure that all team members were on the same page?',\n",
    "    'What tools or methodologies did you use for project management?'],\n",
    "   'why_asked': 'Leadership is key for a senior role, and this question evaluates both skills and experiences related to team management and delivery.',\n",
    "   'relevance_to_cv': \"The candidate's role likely involved collaboration in software development; this will provide insights into their leadership style.\"},\n",
    "  {'question_id': 5,\n",
    "   'question': 'Imagine that your microservices architecture is experiencing performance issues. How would you go about diagnosing and resolving them?',\n",
    "   'category': 'Problem-Solving',\n",
    "   'difficulty': 'medium',\n",
    "   'expected_answer_type': 'analytical',\n",
    "   'estimated_time_minutes': 8,\n",
    "   'key_points': ['Systematic approach to diagnostics',\n",
    "    'Tools or metrics to use',\n",
    "    'Proposed solutions'],\n",
    "   'follow_up_questions': ['What are the potential impacts of these performance issues on business operations?',\n",
    "    'How do you prioritize which issues to tackle first?'],\n",
    "   'why_asked': 'This evaluates critical thinking, analytical skills, and knowledge of microservices, which are essential for the role.',\n",
    "   'relevance_to_cv': \"The candidate's experience with microservices will be critical in understanding their approach to system-wide issues.\"},\n",
    "  {'question_id': 6,\n",
    "   'question': 'In your opinion, what are the key differences between traditional software development approaches and Agile methodologies? How have you applied Agile principles in your previous roles?',\n",
    "   'category': 'Situational',\n",
    "   'difficulty': 'medium',\n",
    "   'expected_answer_type': 'conceptual',\n",
    "   'estimated_time_minutes': 8,\n",
    "   'key_points': ['Clear understanding of Agile principles',\n",
    "    'Examples of Agile applied in a team',\n",
    "    'Impact on project delivery'],\n",
    "   'follow_up_questions': ['Can you give a specific example of a challenge you faced using Agile?',\n",
    "    'How do you handle team dynamics in an Agile environment?'],\n",
    "   'why_asked': 'Understanding Agile is crucial for modern software development, and this question tests the candidateâ€™s adaptability to team processes.',\n",
    "   'relevance_to_cv': \"Faizan's past roles may have required adaptability to team methodologies, making this relevant to collaboration and project success.\"}],\n",
    " 'interview_summary': {'total_questions': 6,\n",
    "  'difficulty_distribution': {'easy': 0, 'medium': 6, 'hard': 0},\n",
    "  'question_categories': ['Behavioral',\n",
    "   'Career Aspirations',\n",
    "   'Technical',\n",
    "   'Leadership',\n",
    "   'Problem-Solving',\n",
    "   'Situational'],\n",
    "  'estimated_interview_duration_minutes': 60}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f42e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(\n",
    "    question: str, \n",
    "    answer: str, \n",
    "    question_category: str, \n",
    "    follow_up_question: list[str],\n",
    "    why_asked: str,\n",
    "):\n",
    "    evaluation_prompt = f\"\"\"\n",
    "    You are an expert interview evaluator. Analyze whether it is relevant to ask a follow-up question based on the candidate's answer.\n",
    "\n",
    "    Instructions:\n",
    "    - Read the interview question and candidate's answer.\n",
    "    - Decide if a follow-up question is necessary to clarify, probe deeper, or evaluate competency.\n",
    "    - Output only a single number between 0 and 10.\n",
    "      - 0 = Follow-up not relevant at all\n",
    "      - 10 = Follow-up extremely relevant and necessary\n",
    "\n",
    "    INTERVIEW QUESTION:\n",
    "    {question}\n",
    "\n",
    "    CANDIDATE ANSWER:\n",
    "    {answer}\n",
    "\n",
    "    QUESTION CATEGORY:\n",
    "    {question_category}\n",
    "\n",
    "    FOLLOW-UP QUESTIONS:\n",
    "    {follow_up_question}\n",
    "\n",
    "    WHY THIS QUESTION WAS ASKED:\n",
    "    {why_asked}\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Output ONLY a single numerical value (0â€“10). No explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Stream response\n",
    "    response_text = \"\"\n",
    "    for chunk in llm.chat_stream(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert interview evaluator.\"},\n",
    "            {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\"\n",
    "    ):\n",
    "        if chunk.get(\"content\"):\n",
    "            response_text += chunk[\"content\"] # type: ignore\n",
    "\n",
    "    # Clean output to extract only number\n",
    "    response_text = response_text.strip()\n",
    "    try:\n",
    "        relevance_score = float(response_text)\n",
    "    except:\n",
    "        relevance_score = 0  # In case model returns unexpected output\n",
    "\n",
    "    return relevance_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "382808b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score = evaluation(\n",
    "    question=\"Tell us about yourself and your career journey.\",\n",
    "    answer=\"I have been working as a FullStack Developer for the past 5 years, focusing on building scalable web applications using Python and JavaScript. My journey started with a passion for coding in high school, which led me to pursue a degree in Computer Science. Over the years, I've worked on various projects, from small startups to large enterprises, honing my skills in both front-end and back-end development. Recently, I transitioned into machine learning, where I've been able to apply my programming skills to develop predictive models and data-driven solutions.\",\n",
    "    question_category=\"Behavioral\",\n",
    "    follow_up_question=[\n",
    "        \"What motivated you to choose a career in software engineering?\",\n",
    "        \"Could you elaborate on a project that significantly impacted your career?\"\n",
    "    ],\n",
    "    why_asked=\"This question helps understand the candidate's background, motivations, and how their experiences have shaped their professional identity.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f461a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Score for Follow-Up Question: 8.0/10\n"
     ]
    }
   ],
   "source": [
    "# if relevance_score < 7.5:\n",
    "#         new_question_prompt = f\"\"\"\n",
    "#         The follow-up questions provided are not relevant enough. Based on the candidate's answer, \n",
    "#         generate ONE better follow-up question that digs deeper, clarifies details, or evaluates competency.\n",
    "\n",
    "#         INTERVIEW QUESTION:\n",
    "#         {question}\n",
    "\n",
    "#         CANDIDATE ANSWER:\n",
    "#         {answer}\n",
    "\n",
    "#         QUESTION CATEGORY:\n",
    "#         {question_category}\n",
    "\n",
    "#         WHY THIS QUESTION WAS ASKED:\n",
    "#         {why_asked}\n",
    "\n",
    "#         IMPORTANT: \n",
    "#         - Return ONLY the new follow-up question.\n",
    "#         - Do NOT include explanations.\n",
    "#         \"\"\"\n",
    "\n",
    "#         new_follow_up = \"\"\n",
    "#         for chunk in llm.chat_stream(\n",
    "#             messages=[\n",
    "#                 {\"role\": \"system\", \"content\": \"You are an expert interview question generator.\"},\n",
    "#                 {\"role\": \"user\", \"content\": new_question_prompt}\n",
    "#             ],\n",
    "#             model=\"gpt-4o-mini\"\n",
    "#         ):\n",
    "#             if chunk.get(\"content\"):\n",
    "#                 new_follow_up += chunk[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df387a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
